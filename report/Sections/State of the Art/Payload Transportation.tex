Cooperative payload transportation is a challenging and emerging field, particularly in a microgravity environment. To address this the state of the art explored in this work focuses not only on microgravity scenarios but also on cooperative payload transportation in terrestrial environments using Unmanned Aerial Vehicles (UAVs).


\subsection{Cooperative Payload Transportation using UAVs}
Numerous studies have investigated the use of UAVs for payload transportation, employing various connection methods such as ball joints~\cite{tagliabue2019robust,loianno2018localization}, robotic arms~\cite{lee2020visual,ouyang2021control}, and cables~\cite{li2021design,klausen2018cooperative,li2023nonlinear}. These systems present significant challenges requiring advanced control algorithms. For instance,~\cite{dhiman2018cooperative} utilizes a double PID controller to regulate both the drone’s movement and the payload’s damping. However, this approach ignores system dynamics due to the controller's limitations. Improvements are seen in~\cite{gimenez2018multi}, where an inverse kinematic controller operating in null space, meaning our actuation space is of higher order than the space we work in, having redundancy, is employed. This method dynamically controls the system while incorporating redundancy in actuation, enabling the targeting of secondary objectives alongside the primary control goal.

Recent advancements in control theory have introduced Model Predictive Controllers (MPCs) and Nonlinear MPCs (NMPCs)~\cite{li2023nonlinear,wehbeh2020distributed}. In~\cite{li2023nonlinear}, an NMPC is used for centralized control of multiple drones. While effective, this centralized approach faces scalability challenges with an increasing number of drones. To overcome this,~\cite{wehbeh2020distributed} proposes a distributed MPC, offering a scalable and efficient solution that ensures optimal performance across multiple drones. 

More recently, with the resurgence of artificial intelligence, particularly Deep Reinforcement Learning (DRL), a novel control framework for payload transportation has emerged~\cite{panetsos2022deep,lin2023payload, belkhale2021model}. The primary advantage of DRL lies in its ability to learn the full dynamics of the system, including coupled dynamics that are difficult to model traditionally. However, this approach has limitations, such as the time and computational resources required for training. Once trained, the DRL model can be deployed across a wide range of scenarios at a lower operational cost compared to traditional methods.

\subsection{Cooperative Payload Transportation in Microgravity Environments}

Payload transportation in microgravity environments remains less explored. Nonetheless, studies on both non-cooperative~\cite{correia2021payload} and cooperative payload transportation~\cite{farivarnejad2021fully,correia2021payload,phodapol2024collaborative} have made progress by modeling connections using ropes or rigid links. These studies highlight the increasing complexity of control algorithms. In~\cite{farivarnejad2021fully}, a simple PID controller was employed for cooperative payload transportation, allowing basic system collaboration without requiring inter-robot communication. However, this approach lacks optimization. To address these limitations, a centralized NMPC was proposed in the same work, demonstrating effectiveness but with constraints related to trajectory generation time and the computation of optimal actuation inputs. In contrast,~\cite{phodapol2024collaborative} introduced a distributed NMPC approach, achieving faster computation times and offering a more scalable solution.

\subsection{Proposed Approach insertion in state of the art}

The proposed approach deviates from recent methods, which typically compute the optimal path for the robot only once and then adjust the control technique to track this reference. In these approaches, changes in the environment during task execution are not considered in the optimization of the path, and the control function must handle such changes in real time. In contrast, the proposed approach adopts a continuous planning technique, where the planner operates in a closed-loop system. This means that, in addition to the control function using the current state of the system to ensure accurate reference tracking, the planner also considers both the current state of the system and the observable environment to maintain the feasibility and optimality of the path. As a result, the control function must track the reference provided by the planner in a safe manner, adapting to changes in the environment

