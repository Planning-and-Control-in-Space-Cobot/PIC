After having the reference trajectory, we now need to be able to control each robot individually during the movement to be able to follow the reference in a safe manner, to do this, a NMPC with the dynamics we can see in equation~\ref{eq:Proposed approach: Controler: NMPC}, our system as we can see has both soft and hard constraint, this since the system parameters needed to be hard constraints, this way we make sure we have no problem with our simulation and control horizon having unfeasible states as this could be a problem. Our soft constraints will be used to make sure our system is safe, by not only penalizing the proximity to a know obstacle, but also to other robots in the grid, meaning some small deviation from the reference will be allowed.  By using a low order integration method we will not have as much precision as using a higher order integration model~\cite{gros2020linear}, but we will have faster computational time, allowing us to have a faster response time. A solution that was found by trial and error to have good results in combating the problem of the low order integration method, speacily for the quaternion representation in the state vector, was forcing the normalization of the quaternion after the integration step for all step in the horizon, this shown to not only have good results, but also having a faster computation time than a higher order method such as the Runge-Kutta method.

\begin{equation}
    \begin{aligned}
        &\underset{x}{\text{minimize}} \quad f(x) + sc(x)\\
        &\text{subject to } x(0) = x_0 \\
        &\quad \quad \quad \quad \, x(k+1) = f(x(k), u(k)) \\ 
        &\quad \quad \quad \quad \, u(k) \in U, \quad k = 0, \dots, N-1
        &\quad \quad \quad \quad \, x(k) \in X, \quad k = 0, \dots, N
    \end{aligned}
    \label{eq:Proposed approach: Controler: NMPC}
\end{equation}

For us to be able to use our NMPC as our control allgorithm, we must be able to work with optimization times in the order of the low millisecond range, as as we can see in~\cite{7400956} off-the-shel algorithm need to be tuned and use some strategies in order to maintain these computation time, as they show, a problem can have solution time ranginng from bellow 1s, to 10s or not even finding a solution by simply changing the solver used in the optimization phase. Taking this into consideration, we real-time scheme was used in our control algorithm, first proposed by~\cite{diehl2002real}, this method perform only 1 SQP iteration per time step, and the calculation are divided between preparation step and feedback step. All operation that are not depended on the knowledge of the current state, are included in the preparation step, since the can be carried offline, reducing the load during the online step. After we have knowledge of the current state, the QP problem is construtdef and solved, giving us a $\Delta u$ and $\Delta x$. With this we can compute the control input as $u = u_{guess} + \Delta u$, and apply it immeasitly to the system, as per~\cite{diehl2005real}. We then need to maintain this control input being applied while we take care of the preparation step, where, as mention earlier, the solution of the previous time step is used as initial guess for the next itteration. By including the initial value embeding and the solving of the QP problem in the feedback problem, we can reduce the feedback time to only the computation time of the solver, as shown in~\cite{gros2020linear}
